WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 0): env://
| distributed init (rank 3): env://
Namespace(data_path='/media/data/coco', dataset='coco', model='retinanet_resnet50_fpn', device='cuda', batch_size=4, weights_path=None, epochs=16, workers=8, opt='sgd', lr=0.01, momentum=0.9, weight_decay=0.0001, norm_weight_decay=None, lr_scheduler='multisteplr', lr_step_size=8, lr_steps=[13, 15], lr_gamma=0.1, print_freq=20, output_dir='.', resume='', start_epoch=0, aspect_ratio_group_factor=3, rpn_score_thresh=None, trainable_backbone_layers=None, data_augmentation='hflip', sync_bn=False, test_only=False, use_deterministic_algorithms=False, world_size=4, dist_url='env://', weights=None, weights_backbone='ResNet50_Weights.IMAGENET1K_V1', amp=False, use_copypaste=False, backend='pil', use_v2=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
Loading data
loading annotations into memory...
Done (t=8.08s)
creating index...
index created!
loading annotations into memory...
Done (t=0.24s)
creating index...
index created!
Creating data loaders
Using [0, 0.5, 0.6299605249474365, 0.7937005259840997, 1.0, 1.259921049894873, 1.5874010519681991, 2.0, inf] as bins for aspect ratio quantization
Count of instances per bin: [  104   982 24236  2332  8225 74466  5763  1158]
Creating model
model : RetinaNet(
  (backbone): BackboneWithFPN(
    (body): IntermediateLayerGetter(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): FrozenBatchNorm2d(64, eps=1e-05)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(64, eps=1e-05)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(64, eps=1e-05)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(256, eps=1e-05)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): FrozenBatchNorm2d(256, eps=1e-05)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(64, eps=1e-05)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(64, eps=1e-05)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(256, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(64, eps=1e-05)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(64, eps=1e-05)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(256, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(128, eps=1e-05)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(128, eps=1e-05)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(512, eps=1e-05)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): FrozenBatchNorm2d(512, eps=1e-05)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(128, eps=1e-05)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(128, eps=1e-05)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(512, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(128, eps=1e-05)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(128, eps=1e-05)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(512, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(128, eps=1e-05)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(128, eps=1e-05)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(512, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(256, eps=1e-05)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(256, eps=1e-05)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): FrozenBatchNorm2d(1024, eps=1e-05)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(256, eps=1e-05)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(256, eps=1e-05)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(256, eps=1e-05)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(256, eps=1e-05)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(256, eps=1e-05)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(256, eps=1e-05)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(256, eps=1e-05)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(256, eps=1e-05)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(256, eps=1e-05)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(256, eps=1e-05)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(512, eps=1e-05)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(512, eps=1e-05)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): FrozenBatchNorm2d(2048, eps=1e-05)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(512, eps=1e-05)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(512, eps=1e-05)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d(512, eps=1e-05)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): FrozenBatchNorm2d(512, eps=1e-05)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (fpn): FeaturePyramidNetwork(
      (inner_blocks): ModuleList(
        (0): Conv2dNormActivation(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Conv2dNormActivation(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (layer_blocks): ModuleList(
        (0-2): 3 x Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (extra_blocks): LastLevelP6P7(
        (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
  )
  (anchor_generator): AnchorGenerator()
  (head): RetinaNetHead(
    (classification_head): RetinaNetClassificationHead(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (2): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
      )
      (cls_logits): Conv2d(256, 819, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (regression_head): RetinaNetRegressionHead(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (2): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
      )
      (bbox_reg): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (transform): GeneralizedRCNNTransform(
      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
      Resize(min_size=(800,), max_size=1333, mode='bilinear')
  )
)
backbone.body.conv1.weight False
backbone.body.layer1.0.conv1.weight False
backbone.body.layer1.0.conv2.weight False
backbone.body.layer1.0.conv3.weight False
backbone.body.layer1.0.downsample.0.weight False
backbone.body.layer1.1.conv1.weight False
backbone.body.layer1.1.conv2.weight False
backbone.body.layer1.1.conv3.weight False
backbone.body.layer1.2.conv1.weight False
backbone.body.layer1.2.conv2.weight False
backbone.body.layer1.2.conv3.weight False
backbone.body.layer2.0.conv1.weight True
backbone.body.layer2.0.conv2.weight True
backbone.body.layer2.0.conv3.weight True
backbone.body.layer2.0.downsample.0.weight True
backbone.body.layer2.1.conv1.weight True
backbone.body.layer2.1.conv2.weight True
backbone.body.layer2.1.conv3.weight True
backbone.body.layer2.2.conv1.weight True
backbone.body.layer2.2.conv2.weight True
backbone.body.layer2.2.conv3.weight True
backbone.body.layer2.3.conv1.weight True
backbone.body.layer2.3.conv2.weight True
backbone.body.layer2.3.conv3.weight True
backbone.body.layer3.0.conv1.weight True
backbone.body.layer3.0.conv2.weight True
backbone.body.layer3.0.conv3.weight True
backbone.body.layer3.0.downsample.0.weight True
backbone.body.layer3.1.conv1.weight True
backbone.body.layer3.1.conv2.weight True
backbone.body.layer3.1.conv3.weight True
backbone.body.layer3.2.conv1.weight True
backbone.body.layer3.2.conv2.weight True
backbone.body.layer3.2.conv3.weight True
backbone.body.layer3.3.conv1.weight True
backbone.body.layer3.3.conv2.weight True
backbone.body.layer3.3.conv3.weight True
backbone.body.layer3.4.conv1.weight True
backbone.body.layer3.4.conv2.weight True
backbone.body.layer3.4.conv3.weight True
backbone.body.layer3.5.conv1.weight True
backbone.body.layer3.5.conv2.weight True
backbone.body.layer3.5.conv3.weight True
backbone.body.layer4.0.conv1.weight True
backbone.body.layer4.0.conv2.weight True
backbone.body.layer4.0.conv3.weight True
backbone.body.layer4.0.downsample.0.weight True
backbone.body.layer4.1.conv1.weight True
backbone.body.layer4.1.conv2.weight True
backbone.body.layer4.1.conv3.weight True
backbone.body.layer4.2.conv1.weight True
backbone.body.layer4.2.conv2.weight True
backbone.body.layer4.2.conv3.weight True
backbone.fpn.inner_blocks.0.0.weight True
backbone.fpn.inner_blocks.0.0.bias True
backbone.fpn.inner_blocks.1.0.weight True
backbone.fpn.inner_blocks.1.0.bias True
backbone.fpn.inner_blocks.2.0.weight True
backbone.fpn.inner_blocks.2.0.bias True
backbone.fpn.layer_blocks.0.0.weight True
backbone.fpn.layer_blocks.0.0.bias True
backbone.fpn.layer_blocks.1.0.weight True
backbone.fpn.layer_blocks.1.0.bias True
backbone.fpn.layer_blocks.2.0.weight True
backbone.fpn.layer_blocks.2.0.bias True
backbone.fpn.extra_blocks.p6.weight True
backbone.fpn.extra_blocks.p6.bias True
backbone.fpn.extra_blocks.p7.weight True
backbone.fpn.extra_blocks.p7.bias True
head.classification_head.conv.0.0.weight True
head.classification_head.conv.0.0.bias True
head.classification_head.conv.1.0.weight True
head.classification_head.conv.1.0.bias True
head.classification_head.conv.2.0.weight True
head.classification_head.conv.2.0.bias True
head.classification_head.conv.3.0.weight True
head.classification_head.conv.3.0.bias True
head.classification_head.cls_logits.weight True
head.classification_head.cls_logits.bias True
head.regression_head.conv.0.0.weight True
head.regression_head.conv.0.0.bias True
head.regression_head.conv.1.0.weight True
head.regression_head.conv.1.0.bias True
head.regression_head.conv.2.0.weight True
head.regression_head.conv.2.0.bias True
head.regression_head.conv.3.0.weight True
head.regression_head.conv.3.0.bias True
head.regression_head.bbox_reg.weight True
head.regression_head.bbox_reg.bias True
model : DistributedDataParallel(
  (module): RetinaNet(
    (backbone): BackboneWithFPN(
      (body): IntermediateLayerGetter(
        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        (bn1): FrozenBatchNorm2d(64, eps=1e-05)
        (relu): ReLU(inplace=True)
        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        (layer1): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(64, eps=1e-05)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(64, eps=1e-05)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(256, eps=1e-05)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): FrozenBatchNorm2d(256, eps=1e-05)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(64, eps=1e-05)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(64, eps=1e-05)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(256, eps=1e-05)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(64, eps=1e-05)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(64, eps=1e-05)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(256, eps=1e-05)
            (relu): ReLU(inplace=True)
          )
        )
        (layer2): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(128, eps=1e-05)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(128, eps=1e-05)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(512, eps=1e-05)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): FrozenBatchNorm2d(512, eps=1e-05)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(128, eps=1e-05)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(128, eps=1e-05)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(512, eps=1e-05)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(128, eps=1e-05)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(128, eps=1e-05)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(512, eps=1e-05)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(128, eps=1e-05)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(128, eps=1e-05)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(512, eps=1e-05)
            (relu): ReLU(inplace=True)
          )
        )
        (layer3): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(256, eps=1e-05)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(256, eps=1e-05)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): FrozenBatchNorm2d(1024, eps=1e-05)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(256, eps=1e-05)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(256, eps=1e-05)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(256, eps=1e-05)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(256, eps=1e-05)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(256, eps=1e-05)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(256, eps=1e-05)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
            (relu): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(256, eps=1e-05)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(256, eps=1e-05)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
            (relu): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(256, eps=1e-05)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(256, eps=1e-05)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
            (relu): ReLU(inplace=True)
          )
        )
        (layer4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(512, eps=1e-05)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(512, eps=1e-05)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): FrozenBatchNorm2d(2048, eps=1e-05)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(512, eps=1e-05)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(512, eps=1e-05)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): FrozenBatchNorm2d(512, eps=1e-05)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): FrozenBatchNorm2d(512, eps=1e-05)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
            (relu): ReLU(inplace=True)
          )
        )
      )
      (fpn): FeaturePyramidNetwork(
        (inner_blocks): ModuleList(
          (0): Conv2dNormActivation(
            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (layer_blocks): ModuleList(
          (0-2): 3 x Conv2dNormActivation(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (extra_blocks): LastLevelP6P7(
          (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        )
      )
    )
    (anchor_generator): AnchorGenerator()
    (head): RetinaNetHead(
      (classification_head): RetinaNetClassificationHead(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (cls_logits): Conv2d(256, 819, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (regression_head): RetinaNetRegressionHead(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
          (2): Conv2dNormActivation(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
          (3): Conv2dNormActivation(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (bbox_reg): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (transform): GeneralizedRCNNTransform(
        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        Resize(min_size=(800,), max_size=1333, mode='bilinear')
    )
  )
)
#Params :  34014999
module.backbone.body.conv1.weight 9408 requires_grad=False
module.backbone.body.layer1.0.conv1.weight 4096 requires_grad=False
module.backbone.body.layer1.0.conv2.weight 36864 requires_grad=False
module.backbone.body.layer1.0.conv3.weight 16384 requires_grad=False
module.backbone.body.layer1.0.downsample.0.weight 16384 requires_grad=False
module.backbone.body.layer1.1.conv1.weight 16384 requires_grad=False
module.backbone.body.layer1.1.conv2.weight 36864 requires_grad=False
module.backbone.body.layer1.1.conv3.weight 16384 requires_grad=False
module.backbone.body.layer1.2.conv1.weight 16384 requires_grad=False
module.backbone.body.layer1.2.conv2.weight 36864 requires_grad=False
module.backbone.body.layer1.2.conv3.weight 16384 requires_grad=False
module.backbone.body.layer2.0.conv1.weight 32768 requires_grad=True
module.backbone.body.layer2.0.conv2.weight 147456 requires_grad=True
module.backbone.body.layer2.0.conv3.weight 65536 requires_grad=True
module.backbone.body.layer2.0.downsample.0.weight 131072 requires_grad=True
module.backbone.body.layer2.1.conv1.weight 65536 requires_grad=True
module.backbone.body.layer2.1.conv2.weight 147456 requires_grad=True
module.backbone.body.layer2.1.conv3.weight 65536 requires_grad=True
module.backbone.body.layer2.2.conv1.weight 65536 requires_grad=True
module.backbone.body.layer2.2.conv2.weight 147456 requires_grad=True
module.backbone.body.layer2.2.conv3.weight 65536 requires_grad=True
module.backbone.body.layer2.3.conv1.weight 65536 requires_grad=True
module.backbone.body.layer2.3.conv2.weight 147456 requires_grad=True
module.backbone.body.layer2.3.conv3.weight 65536 requires_grad=True
module.backbone.body.layer3.0.conv1.weight 131072 requires_grad=True
module.backbone.body.layer3.0.conv2.weight 589824 requires_grad=True
module.backbone.body.layer3.0.conv3.weight 262144 requires_grad=True
module.backbone.body.layer3.0.downsample.0.weight 524288 requires_grad=True
module.backbone.body.layer3.1.conv1.weight 262144 requires_grad=True
module.backbone.body.layer3.1.conv2.weight 589824 requires_grad=True
module.backbone.body.layer3.1.conv3.weight 262144 requires_grad=True
module.backbone.body.layer3.2.conv1.weight 262144 requires_grad=True
module.backbone.body.layer3.2.conv2.weight 589824 requires_grad=True
module.backbone.body.layer3.2.conv3.weight 262144 requires_grad=True
module.backbone.body.layer3.3.conv1.weight 262144 requires_grad=True
module.backbone.body.layer3.3.conv2.weight 589824 requires_grad=True
module.backbone.body.layer3.3.conv3.weight 262144 requires_grad=True
module.backbone.body.layer3.4.conv1.weight 262144 requires_grad=True
module.backbone.body.layer3.4.conv2.weight 589824 requires_grad=True
module.backbone.body.layer3.4.conv3.weight 262144 requires_grad=True
module.backbone.body.layer3.5.conv1.weight 262144 requires_grad=True
module.backbone.body.layer3.5.conv2.weight 589824 requires_grad=True
module.backbone.body.layer3.5.conv3.weight 262144 requires_grad=True
module.backbone.body.layer4.0.conv1.weight 524288 requires_grad=True
module.backbone.body.layer4.0.conv2.weight 2359296 requires_grad=True
module.backbone.body.layer4.0.conv3.weight 1048576 requires_grad=True
module.backbone.body.layer4.0.downsample.0.weight 2097152 requires_grad=True
module.backbone.body.layer4.1.conv1.weight 1048576 requires_grad=True
module.backbone.body.layer4.1.conv2.weight 2359296 requires_grad=True
module.backbone.body.layer4.1.conv3.weight 1048576 requires_grad=True
module.backbone.body.layer4.2.conv1.weight 1048576 requires_grad=True
module.backbone.body.layer4.2.conv2.weight 2359296 requires_grad=True
module.backbone.body.layer4.2.conv3.weight 1048576 requires_grad=True
module.backbone.fpn.inner_blocks.0.0.weight 131072 requires_grad=True
module.backbone.fpn.inner_blocks.0.0.bias 256 requires_grad=True
module.backbone.fpn.inner_blocks.1.0.weight 262144 requires_grad=True
module.backbone.fpn.inner_blocks.1.0.bias 256 requires_grad=True
module.backbone.fpn.inner_blocks.2.0.weight 524288 requires_grad=True
module.backbone.fpn.inner_blocks.2.0.bias 256 requires_grad=True
module.backbone.fpn.layer_blocks.0.0.weight 589824 requires_grad=True
module.backbone.fpn.layer_blocks.0.0.bias 256 requires_grad=True
module.backbone.fpn.layer_blocks.1.0.weight 589824 requires_grad=True
module.backbone.fpn.layer_blocks.1.0.bias 256 requires_grad=True
module.backbone.fpn.layer_blocks.2.0.weight 589824 requires_grad=True
module.backbone.fpn.layer_blocks.2.0.bias 256 requires_grad=True
module.backbone.fpn.extra_blocks.p6.weight 589824 requires_grad=True
module.backbone.fpn.extra_blocks.p6.bias 256 requires_grad=True
module.backbone.fpn.extra_blocks.p7.weight 589824 requires_grad=True
module.backbone.fpn.extra_blocks.p7.bias 256 requires_grad=True
module.head.classification_head.conv.0.0.weight 589824 requires_grad=True
module.head.classification_head.conv.0.0.bias 256 requires_grad=True
module.head.classification_head.conv.1.0.weight 589824 requires_grad=True
module.head.classification_head.conv.1.0.bias 256 requires_grad=True
module.head.classification_head.conv.2.0.weight 589824 requires_grad=True
module.head.classification_head.conv.2.0.bias 256 requires_grad=True
module.head.classification_head.conv.3.0.weight 589824 requires_grad=True
module.head.classification_head.conv.3.0.bias 256 requires_grad=True
module.head.classification_head.cls_logits.weight 1886976 requires_grad=True
module.head.classification_head.cls_logits.bias 819 requires_grad=True
module.head.regression_head.conv.0.0.weight 589824 requires_grad=True
module.head.regression_head.conv.0.0.bias 256 requires_grad=True
module.head.regression_head.conv.1.0.weight 589824 requires_grad=True
module.head.regression_head.conv.1.0.bias 256 requires_grad=True
module.head.regression_head.conv.2.0.weight 589824 requires_grad=True
module.head.regression_head.conv.2.0.bias 256 requires_grad=True
module.head.regression_head.conv.3.0.weight 589824 requires_grad=True
module.head.regression_head.conv.3.0.bias 256 requires_grad=True
module.head.regression_head.bbox_reg.weight 82944 requires_grad=True
module.head.regression_head.bbox_reg.bias 36 requires_grad=True
Start training
module.backbone.body.conv1.weight has no grad, (None)
module.backbone.body.layer1.0.conv1.weight has no grad, (None)
module.backbone.body.layer1.0.conv2.weight has no grad, (None)
module.backbone.body.layer1.0.conv3.weight has no grad, (None)
module.backbone.body.layer1.0.downsample.0.weight has no grad, (None)
module.backbone.body.layer1.1.conv1.weight has no grad, (None)
module.backbone.body.layer1.1.conv2.weight has no grad, (None)
module.backbone.body.layer1.1.conv3.weight has no grad, (None)
module.backbone.body.layer1.2.conv1.weight has no grad, (None)
module.backbone.body.layer1.2.conv2.weight has no grad, (None)
module.backbone.body.layer1.2.conv3.weight has no grad, (None)
module.backbone.body.layer2.0.conv1.weight has no grad, (None)
module.backbone.body.layer2.0.conv2.weight has no grad, (None)
module.backbone.body.layer2.0.conv3.weight has no grad, (None)
module.backbone.body.layer2.0.downsample.0.weight has no grad, (None)
module.backbone.body.layer2.1.conv1.weight has no grad, (None)
module.backbone.body.layer2.1.conv2.weight has no grad, (None)
module.backbone.body.layer2.1.conv3.weight has no grad, (None)
module.backbone.body.layer2.2.conv1.weight has no grad, (None)
module.backbone.body.layer2.2.conv2.weight has no grad, (None)
module.backbone.body.layer2.2.conv3.weight has no grad, (None)
module.backbone.body.layer2.3.conv1.weight has no grad, (None)
module.backbone.body.layer2.3.conv2.weight has no grad, (None)
module.backbone.body.layer2.3.conv3.weight has no grad, (None)
module.backbone.body.layer3.0.conv1.weight has no grad, (None)
module.backbone.body.layer3.0.conv2.weight has no grad, (None)
module.backbone.body.layer3.0.conv3.weight has no grad, (None)
module.backbone.body.layer3.0.downsample.0.weight has no grad, (None)
module.backbone.body.layer3.1.conv1.weight has no grad, (None)
module.backbone.body.layer3.1.conv2.weight has no grad, (None)
module.backbone.body.layer3.1.conv3.weight has no grad, (None)
module.backbone.body.layer3.2.conv1.weight has no grad, (None)
module.backbone.body.layer3.2.conv2.weight has no grad, (None)
module.backbone.body.layer3.2.conv3.weight has no grad, (None)
module.backbone.body.layer3.3.conv1.weight has no grad, (None)
module.backbone.body.layer3.3.conv2.weight has no grad, (None)
module.backbone.body.layer3.3.conv3.weight has no grad, (None)
module.backbone.body.layer3.4.conv1.weight has no grad, (None)
module.backbone.body.layer3.4.conv2.weight has no grad, (None)
module.backbone.body.layer3.4.conv3.weight has no grad, (None)
module.backbone.body.layer3.5.conv1.weight has no grad, (None)
module.backbone.body.layer3.5.conv2.weight has no grad, (None)
module.backbone.body.layer3.5.conv3.weight has no grad, (None)
module.backbone.body.layer4.0.conv1.weight has no grad, (None)
module.backbone.body.layer4.0.conv2.weight has no grad, (None)
module.backbone.body.layer4.0.conv3.weight has no grad, (None)
module.backbone.body.layer4.0.downsample.0.weight has no grad, (None)
module.backbone.body.layer4.1.conv1.weight has no grad, (None)
module.backbone.body.layer4.1.conv2.weight has no grad, (None)
module.backbone.body.layer4.1.conv3.weight has no grad, (None)
module.backbone.body.layer4.2.conv1.weight has no grad, (None)
module.backbone.body.layer4.2.conv2.weight has no grad, (None)
module.backbone.body.layer4.2.conv3.weight has no grad, (None)
module.backbone.fpn.inner_blocks.0.0.weight has no grad, (None)
module.backbone.fpn.inner_blocks.0.0.bias has no grad, (None)
module.backbone.fpn.inner_blocks.1.0.weight has no grad, (None)
module.backbone.fpn.inner_blocks.1.0.bias has no grad, (None)
module.backbone.fpn.inner_blocks.2.0.weight has no grad, (None)
module.backbone.fpn.inner_blocks.2.0.bias has no grad, (None)
module.backbone.fpn.layer_blocks.0.0.weight has no grad, (None)
module.backbone.fpn.layer_blocks.0.0.bias has no grad, (None)
module.backbone.fpn.layer_blocks.1.0.weight has no grad, (None)
module.backbone.fpn.layer_blocks.1.0.bias has no grad, (None)
module.backbone.fpn.layer_blocks.2.0.weight has no grad, (None)
module.backbone.fpn.layer_blocks.2.0.bias has no grad, (None)
module.backbone.fpn.extra_blocks.p6.weight has no grad, (None)
module.backbone.fpn.extra_blocks.p6.bias has no grad, (None)
module.backbone.fpn.extra_blocks.p7.weight has no grad, (None)
module.backbone.fpn.extra_blocks.p7.bias has no grad, (None)
module.head.classification_head.conv.0.0.weight has no grad, (None)
module.head.classification_head.conv.0.0.bias has no grad, (None)
module.head.classification_head.conv.1.0.weight has no grad, (None)
module.head.classification_head.conv.1.0.bias has no grad, (None)
module.head.classification_head.conv.2.0.weight has no grad, (None)
module.head.classification_head.conv.2.0.bias has no grad, (None)
module.head.classification_head.conv.3.0.weight has no grad, (None)
module.head.classification_head.conv.3.0.bias has no grad, (None)
module.head.classification_head.cls_logits.weight has no grad, (None)
module.head.classification_head.cls_logits.bias has no grad, (None)
module.head.regression_head.conv.0.0.weight has no grad, (None)
module.head.regression_head.conv.0.0.bias has no grad, (None)
module.head.regression_head.conv.1.0.weight has no grad, (None)
module.head.regression_head.conv.1.0.bias has no grad, (None)
module.head.regression_head.conv.2.0.weight has no grad, (None)
module.head.regression_head.conv.2.0.bias has no grad, (None)
module.head.regression_head.conv.3.0.weight has no grad, (None)
module.head.regression_head.conv.3.0.bias has no grad, (None)
module.head.regression_head.bbox_reg.weight has no grad, (None)
module.head.regression_head.bbox_reg.bias has no grad, (None)
Epoch: [0]  [   0/7329]  eta: 3:27:03  lr: 0.000020  loss: 2.1838 (2.1838)  bbox_regression: 0.8218 (0.8218)  classification: 1.3620 (1.3620)  time: 1.6951  data: 0.5916  max mem: 5561
module.backbone.body.conv1.weight has no grad, (None)
module.backbone.body.layer1.0.conv1.weight has no grad, (None)
module.backbone.body.layer1.0.conv2.weight has no grad, (None)
module.backbone.body.layer1.0.conv3.weight has no grad, (None)
module.backbone.body.layer1.0.downsample.0.weight has no grad, (None)
module.backbone.body.layer1.1.conv1.weight has no grad, (None)
module.backbone.body.layer1.1.conv2.weight has no grad, (None)
module.backbone.body.layer1.1.conv3.weight has no grad, (None)
module.backbone.body.layer1.2.conv1.weight has no grad, (None)
module.backbone.body.layer1.2.conv2.weight has no grad, (None)
module.backbone.body.layer1.2.conv3.weight has no grad, (None)
module.backbone.body.conv1.weight has no grad, (None)
module.backbone.body.layer1.0.conv1.weight has no grad, (None)
module.backbone.body.layer1.0.conv2.weight has no grad, (None)
module.backbone.body.layer1.0.conv3.weight has no grad, (None)
module.backbone.body.layer1.0.downsample.0.weight has no grad, (None)
module.backbone.body.layer1.1.conv1.weight has no grad, (None)
module.backbone.body.layer1.1.conv2.weight has no grad, (None)
module.backbone.body.layer1.1.conv3.weight has no grad, (None)
module.backbone.body.layer1.2.conv1.weight has no grad, (None)
module.backbone.body.layer1.2.conv2.weight has no grad, (None)
module.backbone.body.layer1.2.conv3.weight has no grad, (None)
